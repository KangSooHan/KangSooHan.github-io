---
title: Collision Detection System
category: sensorfusion
layout: post
use_math: true
---

### Collision Detection System
이번장에서는 Collision Detection System을 하도록 하겠습니다. 이를 위해 시간, 거리, 속도와 가속도를 사용해 sensor의 모션을 재구성합니다. 우리는 간단하고 학습을 위한 용도이기 때문에 속도 또는 가속도는 변하지 않는다는 절대적인 가정을 하고 시작하도록 하겠습니다.

<br>
### The Collision Detection Problem
Collision Avoidance System(CAS)은 운전을 하는 도중에 충돌이 임박했을 때 운전자에게 알려주거나 brake를 동작하는 보조 장치입니다. CAS는 자동차와의 충돌을 평가하기 위해 TTC(time-to-collision)를 계속해서 계산합니다. 아래 그림에서 노란색 차량과 초록색 차량의 거리는 time 0에서의 거리는 $d_{0}$입니다. 이 때 time $t_{0}$에서 초록색 차량이 속도를 줄이게 된다면, time $t_{1}$에서 노락색 차량과 초록색 차량의 거리는 $d_{1}$이 됩니다. 이것을 사용하여 노란색 차량과 초록색 차량의 거리 $d_{i}$가 0이 되는 시간 $t_{i}$가 TTC 입니다.

<br>
#### CVM(Constant Velocity Model)
TTC를 계산하기 위해서 우리는 몇가지 가정이 필요합니다. 첫 번째 가정은 노란색 차량과 초록색 차량의 속도는 constant하다는 것입니다. 이것은 eq.1 번의 CVM(Constant Velocity Model) 모델을 만들어줍니다. 

$ eq 1. \quad d(t+\Delta t) = d(t) - v_{0} \cdot \Delta t$ 

<br>
#### CAM(Constant Acceleration Model)
하지만 CVM만 가지고 모델링을 하게되면 정확도가 매우 낮습니다. 그래서 eq 3.과 같은 velocity와 acceleration의 수식을 사용하여 eq 2.번과 같은 CAM 모델을 만들 수 있습니다.

$ eq 2. \quad d(t+\Delta t) = d(t) - v(t) \cdot \Delta t - \frac{1}{2}a_{0} \cdot \Delta t^{2}$ \
$ eq 3. \quad v(t+\Delta t) = v(t) - a_{0} \cdot \Delta t $

실제 환경에서는 CVM보다 CAM이 훨씬 좋은 성능을 보이지만 우리는 CVM 모델을 기반으로 공부를 하도록 하겠습니다. 

<br>
### Estimating TTC with Lidar
Lidar에서 TTC를 계산하는 것은 아래 그림과 수식처럼 확인할 수 있습니다.(CVM 기반의 Lidar TTC) \
<img src="/assets/img/sensorfusion/Lidar_TTC.jpg" width="50%" height="50%"> \
$ eq 1. \quad d(t+\Delta t)= d(t)-v_{0} \cdot \Delta t $ \
$ eq 2. \quad v_{0}=\frac{d(t) - d(t + \Delta t)}{\Delta t} = \frac{d_{0} - d_{1}}{\Delta t}$ \
$ eq 3. \quad TTC = \frac{d_{1}}{v_{0}} = \frac{d_{1} \cdot \Delta t}{d_{0} - d_{1}} $

<br>
Rader는 상대 속도에 관한 정보를 포함하기 때문에 TTC를 측정할 수 있지만 Lidar로 얻은 point cloud는 depth를 기반으로 계산하기 때문에 두가지 거리 측정을 통해 계산해야 합니다.
* 도로 표면에 있는 measurements를 제거
* low reflectivity measurements를 제거 

<img src="/assets/img/sensorfusion/Remove_Lidar_Point.jpg" width="50%" height="50%">

<br>
### Estimating TTC with a Camera
앞에서 Lidar를 사용한 TTC를 계산하였습니다. 그리고 Lidar를 사용한 TTC 계산은 어려운 부분도 있었지만 매우 강력하게 잘 동작합니다. 이번 장에서는 Camera를 사용한 TTC를 진행합니다. Camera는 3D 측정값을 포함하고 있지 않고, 안정적이고 정확하게 차량의 움직임을 추적하기 위해서 차량을 정확하게 식별해야 합니다. 

<br>
### Measuring TTC without distance
Monocular 카메라는 거리를 측정할 수 없습니다. 왜냐하면 레이더나 라이다 처럼 파장을 쏘는 것이 아닌 주변 빛에 의존하는 Passive Sensor이기 때문입니다. 따라서 거리를 측정하기 위해서는 두번째 카메라가 필요합니다. 정교하게 정렬된 두개의 카메라들(stereo setup이라 불리는)로 얻은 이미지에서 두 이미지의 공통 관심 지점(feature extraction)을 찾은 다음 카메라 기하학 및 perspective projection(투시 투영)을 사용하여 삼각 측량을 진행하면 거리를 계산할 수 있습니다. \
우리는 이제 앞서 배웠던 CVM을 카메라를 통해 계산합니다. 우리는 distance $d$를 이미지 평면에서 픽셀 거리를 통해 획득할 수 있습니다. 아래 그림을 보면 주행중인 자동차의 높이 $H$를 perspective projection을 사용하여 이미지 평면에 매핑시킬 수 있습니다. 이 때, 주행중인 자동차의 높이 $H$는 동일하지만, 거리 $d_{0}$과 $d_{1}$에 따라 이미지 평면에 맺히는 높이 $h_{0}$와 $h_{1}$은 다른 것을 확인할 수 있습니다. 그래서 우리는 명백한 값 $d$를 $h, H$ 그리고 focal length $f$를 통해 얻을 수 있습니다.

<img src="/assets/img/sensorfusion/Camera_TTC_Distance.jpg" width="50%" height="50%">

<br>
**$\qquad$ project object into camera** \
1번 수식에서 우리는 camera의 focal length $f$와 distance measurement $d_{0}$을 통해 높이 $H$의 자동차를 pixel 높이 $h_{0}$를 표현할 수 있습니다. time $t_{1}$에서도 동일합니다. \
$Eq 1. \quad h_{0} = \frac{f \cdot H}{d_{0}}; h_{1} = \frac{f \cdot H}{d_{1}} $ 

<br>
**$\qquad$ relate projection and distance** \
2번 수식에서 우리는 $h_{1}$과 $h_{0}$의 비율을 계산하고 Eq 1.을 사용하여 $d_{0}$과 $d_{1}$의 관계도 표현할 수 있습니다. \
$Eq 2. \quad \frac{h_{1}}{h_{0}} = \frac{\frac{f \cdot H}{d_{1}}}{\frac{f \cdot H}{d_{0}}} = \frac{d_{0}}{d_{1}} \rightarrow d_{0} = d_{1} \cdot \frac{h_{1}}{h_{0}} $ 


<br>
**$\qquad$ substitute in constant-velocity model** \
3번 수식에서 CVM에서 $d_{0}$을 대체하여 $d_{1}$을 풀 수 있습니다. 이렇게 하면 우리는 velocity $v_{0}$, image plane에 맺히는 차의 pixel 높이 $h_{0}, h_{1}$로 $d_{1}$을 표현할 수 있습니다. \
$Eq 3. \quad d_{1} = d_{0} - v_{0} \cdot \Delta t = d_{1} \cdot \frac{h_{1}}{h_{0}} - v_{0} \cdot \Delta t $\
$ \qquad\quad d_{1} = \frac{-v_{0} \cdot \Delta t}{(1-\frac{h_{1}}{h_{0}}} $

<br>
**$\qquad$ compuote time to contact / collision** \
4번 수식에서는 앞서 얻은 $d_{1}$을 기반으로 TTC를 계산할 수 있습니다. 그러면 최종적으로 $h_{1}, h_{0}$을 통해서 TTC를 계산할 수 있는 수식을 획득할 수 있습니다.\
$Eq 4. \quad TTC = \frac{d_{1}}{v_{0}} = \frac{-\Delta t}{(1-\frac{h_{1}}{h_{0}})}$ 

그러므로 그러므로 우리는 이미지 센서를 통해 얻은 이미지 pixel의 높이 변화(relative height, scale change)만을 관찰하여 TTC를 계산할 수 있습니다.


<br>
### Using Texture Keypoints Instead
NN로 계산한 Bounding Box는 계속해서 크기가 변경이 되어 정확한 결과를 얻기 어렵습니다. 이러한 문제는 TTC를 계산할 때 큰 에러를 가져올 수 있습니다. 그래서 우리는 uniquely identifiable keypoints를 찾고 이 keypoints를 통해 높이를 계산하도록 하겠습니다. 

<p align="center"<img src="/assets/img/sensorfusion/Camera_KeyPoint_TTC.jpg" width="60%" height="60%"></p>

그림(a)에서 자동차에 7가지의 keypoints를 찾았습니다. 그림 (b)에서는 descriptor라 불리는 higher-dimensional similarity measure를 사용하여 4개의 keypoints가 매칭이 되었습니다. 우리는 여기서 얻은 $d_{k}$ 값들의 평균 혹은 중앙 값으로 TTC를 계산합니다.\





<br><br><br><br><br>

----
### 단어
Imminent : 임박한 \
Tailgate : 뒷문, 바짝 따라 달리다 \
Deviation : 편차 \
Curvature : 곡선의 \
Substitute : 대체하다 
